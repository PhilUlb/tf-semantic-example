{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PoNSZn1D7d8J"
   },
   "source": [
    "# Semantic Segmentation with tf.data in TensorFlow 2 and ADE20K dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KnA3joV7nVR"
   },
   "source": [
    "In this notebook we are going to cover the usage of tensorflow 2 and tf.data on a popular semantic segmentation 2D images dataset: ADE20K.\n",
    "\n",
    "The type of data we are going to manipulate consist in:\n",
    "* an jpg image with 3 channels (RGB)\n",
    "* a jpg mask with 1 channel (for each pixel we have 1 true class over 150 possible)  \n",
    "\n",
    "You can also find all the information by reading the official tensorflow tutorials:\n",
    "\n",
    "* https://www.tensorflow.org/tutorials/load_data/images\n",
    "* https://www.tensorflow.org/tutorials/images/segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes that your environment is Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "53uMkooT79_4"
   },
   "source": [
    "## 2. Preparing the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lCFAUR97ZDR"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import shutil\n",
    "import argparse\n",
    "import zipfile\n",
    "import hashlib\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from IPython.display import clear_output\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# For more information about autotune:\n",
    "# https://www.tensorflow.org/guide/data_performance#prefetching\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "print(f\"Tensorflow ver. {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGKYiwWM7my6"
   },
   "outputs": [],
   "source": [
    "# important for reproducibility\n",
    "# this allows to generate the same random numbers\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Downloading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement a small tool to download ADE2k in colab environment directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can load your own Google Drive to avoid re-dowloading the dataset\n",
    "# In this case you will have to modify the path \"root\" in the next steps\n",
    "\n",
    "# Uncomment those 2 lines to use your own Google drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions to download the dataset\n",
    "# this code comes mainly from gluoncv.utils\n",
    "def check_sha1(filename, sha1_hash):\n",
    "    \"\"\"Check whether the sha1 hash of the file content matches the expected hash.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the file.\n",
    "    sha1_hash : str\n",
    "        Expected sha1 hash in hexadecimal digits.\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        Whether the file content matches the expected hash.\n",
    "    \"\"\"\n",
    "    sha1 = hashlib.sha1()\n",
    "    with open(filename, 'rb') as f:\n",
    "        while True:\n",
    "            data = f.read(1048576)\n",
    "            if not data:\n",
    "                break\n",
    "            sha1.update(data)\n",
    "\n",
    "    sha1_file = sha1.hexdigest()\n",
    "    l = min(len(sha1_file), len(sha1_hash))\n",
    "    return sha1.hexdigest()[0:l] == sha1_hash[0:l]\n",
    "\n",
    "def download(url, path=None, overwrite=False, sha1_hash=None):\n",
    "    \"\"\"Download an given URL\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        URL to download\n",
    "    path : str, optional\n",
    "        Destination path to store downloaded file. By default stores to the\n",
    "        current directory with same name as in url.\n",
    "    overwrite : bool, optional\n",
    "        Whether to overwrite destination file if already exists.\n",
    "    sha1_hash : str, optional\n",
    "        Expected sha1 hash in hexadecimal digits. Will ignore existing file when hash is specified\n",
    "        but doesn't match.\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The file path of the downloaded file.\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        fname = url.split('/')[-1]\n",
    "    else:\n",
    "        path = os.path.expanduser(path)\n",
    "        if os.path.isdir(path):\n",
    "            fname = os.path.join(path, url.split('/')[-1])\n",
    "        else:\n",
    "            fname = path\n",
    "\n",
    "    if overwrite or not os.path.exists(fname) or (sha1_hash and not check_sha1(fname, sha1_hash)):\n",
    "        dirname = os.path.dirname(os.path.abspath(os.path.expanduser(fname)))\n",
    "        if not os.path.exists(dirname):\n",
    "            os.makedirs(dirname)\n",
    "\n",
    "        print('Downloading %s from %s...'%(fname, url))\n",
    "        r = requests.get(url, stream=True)\n",
    "        if r.status_code != 200:\n",
    "            raise RuntimeError(\"Failed downloading url %s\"%url)\n",
    "        total_length = r.headers.get('content-length')\n",
    "        with open(fname, 'wb') as f:\n",
    "            if total_length is None: # no content length header\n",
    "                for chunk in r.iter_content(chunk_size=1024):\n",
    "                    if chunk: # filter out keep-alive new chunks\n",
    "                        f.write(chunk)\n",
    "            else:\n",
    "                total_length = int(total_length)\n",
    "                for chunk in tqdm(r.iter_content(chunk_size=1024),\n",
    "                                  total=int(total_length / 1024. + 0.5),\n",
    "                                  unit='KB', unit_scale=False, dynamic_ncols=True):\n",
    "                    f.write(chunk)\n",
    "\n",
    "        if sha1_hash and not check_sha1(fname, sha1_hash):\n",
    "            raise UserWarning('File {} is downloaded but the content hash does not match. ' \\\n",
    "                              'The repo may be outdated or download may be incomplete. ' \\\n",
    "                              'If the \"repo_url\" is overridden, consider switching to ' \\\n",
    "                              'the default repo.'.format(fname))\n",
    "\n",
    "    return fname\n",
    "\n",
    "def download_ade(path, overwrite=False):\n",
    "\n",
    "    \"\"\"Download ADE20K\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "      Location of the downloaded files.\n",
    "    overwrite : bool, optional\n",
    "      Whether to overwrite destination file if already exists.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    _AUG_DOWNLOAD_URLS = [\n",
    "      ('http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip', '219e1696abb36c8ba3a3afe7fb2f4b4606a897c7'),\n",
    "      ('http://data.csail.mit.edu/places/ADEchallenge/release_test.zip', 'e05747892219d10e9243933371a497e905a4860c'),]\n",
    "    download_dir = os.path.join(path, 'downloads')\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.mkdir(download_dir)\n",
    "    for url, checksum in _AUG_DOWNLOAD_URLS:\n",
    "        filename = download(url, path=download_dir, overwrite=overwrite, sha1_hash=checksum)\n",
    "        # extract\n",
    "        with zipfile.ZipFile(filename,\"r\") as zip_ref:\n",
    "            zip_ref.extractall(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VW3jgp_1_q-6"
   },
   "outputs": [],
   "source": [
    "root = \"/content/\"\n",
    "dataset_path = root + \"ADEChallengeData2016/images/\"\n",
    "training_data = \"training/\"\n",
    "val_data = \"validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_ade(root, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yocgxYITGXSv"
   },
   "source": [
    "## 3. Creating our Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-KqCjhW6-Rdl"
   },
   "outputs": [],
   "source": [
    "# Image size that we are going to use\n",
    "IMG_SIZE = 128\n",
    "# Our images are RGB (3 channels)\n",
    "N_CHANNELS = 3\n",
    "# Scene Parsing has 150 classes + `not labeled`\n",
    "N_CLASSES = 151"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Creating a source dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7znO6EafQs8S",
    "outputId": "816b761b-2967-45b6-ef02-d4cffbfe17c4"
   },
   "outputs": [],
   "source": [
    "TRAINSET_SIZE = len(glob(dataset_path + training_data + \"*.jpg\"))\n",
    "print(f\"The Training Dataset contains {TRAINSET_SIZE} images.\")\n",
    "\n",
    "VALSET_SIZE = len(glob(dataset_path + val_data + \"*.jpg\"))\n",
    "print(f\"The Validation Dataset contains {VALSET_SIZE} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3IeIvttGer6"
   },
   "source": [
    "For each images of our dataset, we will apply some operations wrapped into a function. Then we will map the whole dataset with this function.   \n",
    "\n",
    "So let's write this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REeU48WsGub0"
   },
   "outputs": [],
   "source": [
    "def parse_image(img_path: str) -> dict:\n",
    "    \"\"\"Load an image and its annotation (mask) and returning\n",
    "    a dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_path : str\n",
    "        Image (not the mask) location.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping an image and its annotation.\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "    # For one Image path:\n",
    "    # .../trainset/images/training/ADE_train_00000001.jpg\n",
    "    # Its corresponding annotation path is:\n",
    "    # .../trainset/annotations/training/ADE_train_00000001.png\n",
    "    mask_path = tf.strings.regex_replace(img_path, \"images\", \"annotations\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"jpg\", \"png\")\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    # The masks contain a class index for each pixels\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    # In scene parsing, \"not labeled\" = 255\n",
    "    # But it will mess up with our N_CLASS = 150\n",
    "    # Since 255 means the 255th class\n",
    "    # Which doesn't exist\n",
    "    mask = tf.where(mask == 255, np.dtype('uint8').type(0), mask)\n",
    "    # Note that we have to convert the new value (0)\n",
    "    # With the same dtype than the tensor itself\n",
    "\n",
    "    return {'image': image, 'segmentation_mask': mask}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you would like to load any other image format, you should modify the `parse_image` function. TensorFlow I/O provide additional tools that might help you. \n",
    "For example, in the case of loading TIFF images, you can use:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import tensorflow.io as tfio\n",
    "...\n",
    "def parse_image(img_path: str) -> dict:\n",
    "...\n",
    "image = tf.io.read_file(img_path)\n",
    "tfio.experimental.image.decode_tiff(image)\n",
    "...\n",
    "```\n",
    "\n",
    "In this case, don't forget to modify the number of channels when implementing the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Vpo8nhYGwy6"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.list_files(dataset_path + training_data + \"*.jpg\", seed=SEED)\n",
    "train_dataset = train_dataset.map(parse_image)\n",
    "\n",
    "val_dataset = tf.data.Dataset.list_files(dataset_path + val_data + \"*.jpg\", seed=SEED)\n",
    "val_dataset =val_dataset.map(parse_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Applying some transformations to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0Pa1mgPSSOL"
   },
   "outputs": [],
   "source": [
    "# Here we are using the decorator @tf.function\n",
    "# if you want to know more about it:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/function\n",
    "\n",
    "@tf.function\n",
    "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
    "    \"\"\"Rescale the pixel values of the images between 0.0 and 1.0\n",
    "    compared to [0,255] originally.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_image : tf.Tensor\n",
    "        Tensorflow tensor containing an image of size [SIZE,SIZE,3].\n",
    "    input_mask : tf.Tensor\n",
    "        Tensorflow tensor containing an annotation of size [SIZE,SIZE,1].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Normalized image and its annotation.\n",
    "    \"\"\"\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(datapoint: dict) -> tuple:\n",
    "    \"\"\"Apply some transformations to an input dictionary\n",
    "    containing a train image and its annotation.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    An annotation is a regular  channel image.\n",
    "    If a transformation such as rotation is applied to the image,\n",
    "    the same transformation has to be applied on the annotation also.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datapoint : dict\n",
    "        A dict containing an image and its annotation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A modified image and its annotation.\n",
    "    \"\"\"\n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def load_image_test(datapoint: dict) -> tuple:\n",
    "    \"\"\"Normalize and resize a test image and its annotation.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Since this is for the test set, we don't need to apply\n",
    "    any data augmentation technique.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datapoint : dict\n",
    "        A dict containing an image and its annotation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A modified image and its annotation.\n",
    "    \"\"\"\n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "J0BpQ8uwHXwb",
    "outputId": "1051e4aa-6daa-4148-e2a1-f8ca2c9b813c"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "# for reference about the BUFFER_SIZE in shuffle:\n",
    "# https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = {\"train\": train_dataset, \"val\": val_dataset}\n",
    "\n",
    "# -- Train Dataset --#\n",
    "dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
    "dataset['train'] = dataset['train'].repeat()\n",
    "dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
    "dataset['train'] = dataset['train'].prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "#-- Validation Dataset --#\n",
    "dataset['val'] = dataset['val'].map(load_image_test)\n",
    "dataset['val'] = dataset['val'].repeat()\n",
    "dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
    "dataset['val'] = dataset['val'].prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(dataset['train'])\n",
    "print(dataset['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QeICDrVjS4ig"
   },
   "source": [
    "## 4. Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems everything is fine. It can be very hard to build your model by having bugs in your dataset. This makes the development process very painful since the potential bugs from your model are adding up to the potential bugs in your dataloaders. Therefore, it is recommended to make sure that you have what you expect.  \n",
    "For that, we are going to develop simple functions to vizualize the content of our dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample(display_list):\n",
    "    \"\"\"Show side-by-side an input image,\n",
    "    the ground truth and the prediction.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(18, 18))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in dataset['train'].take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "display_sample([sample_image[0], sample_mask[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensions are the ones we expect and it shows up properly. We can start the development of the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Developing the Model (UNet) Using Keras Functional API\n",
    "For this example, we are going to implement a popular architecture: UNet. In a sense, it is not the best for a titorial since this model is very heavy. But I found the exercise interesting. Especially because we are going to use the functional API provided by keras.\n",
    "\n",
    "This architecture was introduce in the paper **U-Net: Convolutional Networks for Biomedical Image Segmentation** that you can read there: https://arxiv.org/abs/1505.04597  \n",
    "\n",
    "You can also read my notes on this paper there: https://yann-leguilly.gitlab.io/post/2019-12-11-unet-biomedical-images/   \n",
    "Basically we are going to reproduce this:  \n",
    "\n",
    "![figure 1](https://yann-leguilly.gitlab.io/img/unet_1/figure_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Keras Functional API -- #\n",
    "# -- UNet Implementation -- #\n",
    "# Everything here is from tensorflow.keras.layers\n",
    "# I imported tensorflow.keras.layers * to make it easier to read\n",
    "dropout_rate = 0.5\n",
    "input_size = (IMG_SIZE, IMG_SIZE, N_CHANNELS)\n",
    "\n",
    "# If you want to know more about why we are using `he_normal`: \n",
    "# https://stats.stackexchange.com/questions/319323/whats-the-difference-between-variance-scaling-initializer-and-xavier-initialize/319849#319849  \n",
    "# Or the excelent fastai course: \n",
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/02b_initializing.ipynb\n",
    "initializer = 'he_normal'\n",
    "\n",
    "\n",
    "# -- Encoder -- #\n",
    "# Block encoder 1\n",
    "inputs = Input(shape=input_size)\n",
    "conv_enc_1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer=initializer)(inputs)\n",
    "conv_enc_1 = Conv2D(64, 3, activation = 'relu', padding='same', kernel_initializer=initializer)(conv_enc_1)\n",
    "\n",
    "# Block encoder 2\n",
    "max_pool_enc_2 = MaxPooling2D(pool_size=(2, 2))(conv_enc_1)\n",
    "conv_enc_2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(max_pool_enc_2)\n",
    "conv_enc_2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_enc_2)\n",
    "\n",
    "# Block  encoder 3\n",
    "max_pool_enc_3 = MaxPooling2D(pool_size=(2, 2))(conv_enc_2)\n",
    "conv_enc_3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(max_pool_enc_3)\n",
    "conv_enc_3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_enc_3)\n",
    "\n",
    "# Block  encoder 4\n",
    "max_pool_enc_4 = MaxPooling2D(pool_size=(2, 2))(conv_enc_3)\n",
    "conv_enc_4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(max_pool_enc_4)\n",
    "conv_enc_4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_enc_4)\n",
    "# -- Encoder -- #\n",
    "\n",
    "# ----------- #\n",
    "maxpool = MaxPooling2D(pool_size=(2, 2))(conv_enc_4)\n",
    "conv = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(maxpool)\n",
    "conv = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv)\n",
    "# ----------- #\n",
    "\n",
    "# -- Dencoder -- #\n",
    "# Block decoder 1\n",
    "up_dec_1 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv))\n",
    "merge_dec_1 = concatenate([conv_enc_4, up_dec_1], axis = 3)\n",
    "conv_dec_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_1)\n",
    "conv_dec_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_1)\n",
    "\n",
    "# Block decoder 2\n",
    "up_dec_2 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv_dec_1))\n",
    "merge_dec_2 = concatenate([conv_enc_3, up_dec_2], axis = 3)\n",
    "conv_dec_2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_2)\n",
    "conv_dec_2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_2)\n",
    "\n",
    "# Block decoder 3\n",
    "up_dec_3 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv_dec_2))\n",
    "merge_dec_3 = concatenate([conv_enc_2, up_dec_3], axis = 3)\n",
    "conv_dec_3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_3)\n",
    "conv_dec_3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_3)\n",
    "\n",
    "# Block decoder 4\n",
    "up_dec_4 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv_dec_3))\n",
    "merge_dec_4 = concatenate([conv_enc_1, up_dec_4], axis = 3)\n",
    "conv_dec_4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_4)\n",
    "conv_dec_4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_4)\n",
    "conv_dec_4 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_4)\n",
    "# -- Dencoder -- #\n",
    "\n",
    "output = Conv2D(N_CLASSES, 1, activation = 'softmax')(conv_dec_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load and compile the model to make sure that there is no bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sfh1cVtt1Y12"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs = inputs, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TlAIZzR600uK"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ekf2x5FS_df"
   },
   "source": [
    "### 5.2. Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize a sample prediction to be sure that we see what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "RCeYBs5ldoJx",
    "outputId": "be3cf105-6c61-4e8b-d55b-3ae06f98da7f"
   },
   "outputs": [],
   "source": [
    "def create_mask(pred_mask: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Return a filter mask with the top 1 predicitons\n",
    "    only.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred_mask : tf.Tensor\n",
    "        A [IMG_SIZE, IMG_SIZE, N_CLASS] tensor. For each pixel we have\n",
    "        N_CLASS values (vector) which represents the probability of the pixel\n",
    "        being these classes. Example: A pixel with the vector [0.0, 0.0, 1.0]\n",
    "        has been predicted class 2 with a probability of 100%.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.Tensor\n",
    "        A [IMG_SIZE, IMG_SIZE, 1] mask with top 1 predictions\n",
    "        for each pixels.\n",
    "    \"\"\"\n",
    "    # pred_mask -> [IMG_SIZE, SIZE, N_CLASS]\n",
    "    # 1 prediction for each class but we want the highest score only\n",
    "    # so we use argmax\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    # pred_mask becomes [IMG_SIZE, IMG_SIZE]\n",
    "    # but matplotlib needs [IMG_SIZE, IMG_SIZE, 1]\n",
    "    pred_mask = tf.expand_dims(pred_mask, axis=-1)\n",
    "    return pred_mask\n",
    "    \n",
    "def show_predictions(dataset=None, num=1):\n",
    "    \"\"\"Show a sample prediction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : [type], optional\n",
    "        [Input dataset, by default None\n",
    "    num : int, optional\n",
    "        Number of sample to show, by default 1\n",
    "    \"\"\"\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display_sample([image[0], true_mask, create_mask(pred_mask)])\n",
    "    else:\n",
    "        # The model is expecting a tensor of the size\n",
    "        # [BATCH_SIZE, IMG_SIZE, IMG_SIZE, 3]\n",
    "        # but sample_image[0] is [IMG_SIZE, IMG_SIZE, 3]\n",
    "        # and we want only 1 inference to be faster\n",
    "        # so we add an additional dimension [1, IMG_SIZE, IMG_SIZE, 3]\n",
    "        one_img_batch = sample_image[0][tf.newaxis, ...]\n",
    "        # one_img_batch -> [1, IMG_SIZE, IMG_SIZE, 3]\n",
    "        inference = model.predict(one_img_batch)\n",
    "        # inference -> [1, IMG_SIZE, IMG_SIZE, N_CLASS]\n",
    "        pred_mask = create_mask(inference)\n",
    "        # pred_mask -> [1, IMG_SIZE, IMG_SIZE, 1]\n",
    "        display_sample([sample_image[0], sample_mask[0],\n",
    "                        pred_mask[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in dataset['train'].take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The far right image is a prediction with random weights. We are ready to start the training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Simpler training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a simple training loop with only 1 epoch first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lg8SkdewgOiP"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "STEPS_PER_EPOCH = TRAINSET_SIZE // BATCH_SIZE\n",
    "VALIDATION_STEPS = VALSET_SIZE // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCUBmThngQ0g"
   },
   "outputs": [],
   "source": [
    "# sometimes it can be very interesting to run some batches on cpu\n",
    "# because the tracing is way better than on GPU\n",
    "# you will have more obvious error message\n",
    "# but in our case, it takes A LOT of time\n",
    "\n",
    "# On CPU\n",
    "# with tf.device(\"/cpu:0\"):\n",
    "#     model_history = model.fit(dataset['train'], epochs=EPOCHS,\n",
    "#                               steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#                               validation_steps=VALIDATION_STEPS,\n",
    "#                               validation_data=dataset['val'])\n",
    "\n",
    "# On GPU\n",
    "model_history = model.fit(dataset['train'], epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=dataset['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks great! We can start our 'real' training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. More Advanced Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras implements what we call 'callbacks'. We can use them to run custom functions at any step of the training. Here we are going to show the output of the model compared to the original image and the ground truth after each epochs.\n",
    "We are also going to collect some useful metrics to make sure our training is happening well by using tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zten6PA0t_fQ"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, loss, callbacks):\n",
    "    model.compile(optimizer=optimizer, loss = loss,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(dataset['train'], epochs=EPOCHS,\n",
    "              steps_per_epoch=STEPS_PER_EPOCH,\n",
    "              validation_steps=VALIDATION_STEPS,\n",
    "              validation_data=dataset['val'],\n",
    "              callbacks=callbacks)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wg_kxEQef_or"
   },
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "callbacks = [\n",
    "    # to show samples after each epoch\n",
    "    DisplayCallback(),\n",
    "    # to collect some useful metrics and visualize them in tensorboard\n",
    "    tensorboard_callback,\n",
    "    # if no accuracy improvements we can stop the training directly\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "    # to save checkpoints\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_model_unet.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = output)\n",
    "\n",
    "# here I'm using a new optimizer: https://arxiv.org/abs/1908.03265\n",
    "optimizer=tfa.optimizers.RectifiedAdam(lr=1e-3)\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model, optimizer, loss, callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "semantic_segmentation_tf2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}